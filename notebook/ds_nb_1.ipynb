{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DeepMatter Data Science/Cheminformatician Interview Notebook\n",
    "\n",
    "This Jupyter notebook contains tasks to be completed prior to your second interview, and is expected to take\n",
    "2-3 hours. Please complete it as necessary and be prepared to discuss it at the interview. Code should be\n",
    "completed using Python, unless a viable/better/justifiable alternative exists."
   ],
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environmental Setup\n",
    "\n",
    "Projects in DeepMatter are structured using Anaconda and Pipenv. As these questions will\n",
    "make use of RDKit, Anaconda is the preferred virtual environment setup. Before you continue,\n",
    "please install Anaconda and create an environment named \"dm_interview\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1 - Runtime Sensor Data\n",
    "\n",
    "Clone the `dm_datascience` repository located on Github at\n",
    "https://github.com/deepmatterltd/dm_datascience, and unzip the data located under\n",
    "`02_PCML_and_PCRR/data/pcrr.zip`.\n",
    "\n",
    "PCRR (Practical Chemistry Runtime Record) files are an XML-based method of capturing all data\n",
    "associated with a chemistry run in our product DigitalGlassware. They capture things such as the\n",
    "operations associated with the reaction, the reagents, the product, the final yield and other outcomes.\n",
    "They also contain observations such as textual and photo notes, as well as timestamps associated\n",
    "with when each operation was performed (e.g. *add 5mg of catalyst X to reactor vessel*)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "0. Download and Extract Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# clone repo\n",
    "dm_datascience_repo_dir = \"../dm_datascience\"\n",
    "if not os.path.isdir(dm_datascience_repo_dir): # only clone if the directory doesn't exist already\n",
    "    !git clone https://github.com/deepmatterltd/dm_datascience $dm_datascience_repo_dir\n",
    "\n",
    "\n",
    "zip_file_path = os.path.join(dm_datascience_repo_dir, \"02_PCML_and_PCRR\", \"data\", \"pcrr.zip\") # location of target zip file\n",
    "pccr_dir = os.path.join(\"..\", \"pcrr\") # target extraction directory\n",
    "\n",
    "# extract zip file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(pccr_dir)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. For each of the PCRR files in the run, extract the name of the recipe, author and number of\n",
    "operations in the recipe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import pathlib\n",
    "import xml.dom.pulldom as pulldom\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "\n",
    "pccr_file_ext = \".pcrr\"\n",
    "pccr_files = os.listdir(pccr_dir) # get all files in the directory\n",
    "\n",
    "recipe_information = []\n",
    "for pccr_file in pccr_files: # iterate over each file\n",
    "\n",
    "    if pathlib.Path(pccr_file).suffix != pccr_file_ext:\n",
    "        print(f\"{pccr_file} is not a .pccr file, skipping.\")\n",
    "        continue\n",
    "    \n",
    "    pccr_file_path = os.path.join(pccr_dir,pccr_file) # get the full path\n",
    "\n",
    "    doc = pulldom.parse(pccr_file_path) # these xml files are very large, use pulldom to extract the parts we need \n",
    "    for event, node in doc:\n",
    "        if event == pulldom.START_ELEMENT and node.tagName == \"recipe_version\": # all required information is within this tag\n",
    "            doc.expandNode(node) # expand the node so we can parse it with elementree and xpath\n",
    "            root = ET.fromstring(node.toxml())  # load the xml into elementree\n",
    "\n",
    "            # use xpath to find recipe name and author\n",
    "            name = root.find(\"./recipe\").attrib[\"name\"]\n",
    "            author = root.find(\"./pcml/meta/author\").text\n",
    "\n",
    "            # use xpath to find all operation tags, and then count them\n",
    "            operations = len(root.findall(\"./pcml/step/group/operation\"))\n",
    "            recipe_information.append({\"filename\":pccr_file, \"name\": name, \"author\": author, \"operations\": operations})\n",
    "\n",
    "            break # we don't need any more information, stop processing the file\n",
    "            \n",
    "print(json.dumps(recipe_information, indent=4))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\n",
      "    {\n",
      "        \"filename\": \"3a_run_02.pcrr\",\n",
      "        \"name\": \"3a) Synthesis of N-(1-Naphthoyl)-4-methylbenzenesulfonohydrazide\",\n",
      "        \"author\": \"Deepmatter\",\n",
      "        \"operations\": 84\n",
      "    },\n",
      "    {\n",
      "        \"filename\": \"3a_run_03.pcrr\",\n",
      "        \"name\": \"3a) Synthesis of N-(1-Naphthoyl)-4-methylbenzenesulfonohydrazide\",\n",
      "        \"author\": \"Deepmatter\",\n",
      "        \"operations\": 84\n",
      "    },\n",
      "    {\n",
      "        \"filename\": \"3a_run_01.pcrr\",\n",
      "        \"name\": \"3a) Synthesis of N-(1-Naphthoyl)-4-methylbenzenesulfonohydrazide\",\n",
      "        \"author\": \"Deepmatter\",\n",
      "        \"operations\": 84\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. XML is great for explicitly structuring data, but not much fun to handle for signal processing.\n",
    "Write a function which can take in a PCRR filename and sensor name (e.g. `irObjTempI` for immersed temperature, or\n",
    "`uvaI` for immersed UVA level) and returns the data a Pandas Series of length N. Note that each sensor\n",
    "reading in the XML has a timestamp associated with it. This timestamp should also be parsed and assigned\n",
    "to the index of the Series object returned."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_sensor_data(pcrr_file_path:str,\n",
    "                        sensor_name:str,\n",
    "                        stop_after_first:bool=False):\n",
    "    \"\"\"Extracts values and timestamps from the given pcrr file and sensor.\n",
    "    pccr_file_path: Path to the pcrr file\n",
    "    sensor_name: The name of the sensor to read data for\n",
    "    stop_after_first: Defaults to False. Set True to stop parsing the document after the first instance of the sensor is found.\n",
    "    \"\"\"\n",
    "    \n",
    "    pccr_file_ext = \".pcrr\"\n",
    "    if pathlib.Path(pccr_file).suffix != pccr_file_ext:\n",
    "        print(f\"{pccr_file} is not a .pccr file, aborting.\")\n",
    "        return None\n",
    "\n",
    "    sensor_data_value = []\n",
    "    sensor_data_timestamp = []\n",
    "\n",
    "    doc = pulldom.parse(pcrr_file_path) # these xml files are very large, use pulldom to extract the parts we need\n",
    "    for event, node in doc:\n",
    "        if event == pulldom.START_ELEMENT:\n",
    "            if node.tagName == \"sensor_data\" and node.getAttribute(\"name\") == sensor_name:\n",
    "                doc.expandNode(node)\n",
    "                root = ET.fromstring(node.toxml())\n",
    "\n",
    "                sensor_data_value += [x.text for x in root.findall(\"./sensor_data_record/value\")]\n",
    "                sensor_data_timestamp += [x.text for x in root.findall(\"./sensor_data_record/timestamp\")]\n",
    "\n",
    "                if stop_after_first:\n",
    "                    break\n",
    "\n",
    "    df = pd.DataFrame(data={sensor_name: sensor_data_value, \"timestamp\": sensor_data_timestamp})\n",
    "    df = df.astype({sensor_name: float, \"timestamp\": \"datetime64[ns]\"})\n",
    "    df.set_index(\"timestamp\", inplace=True)\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Use the function to extract immersed temperature (`irObjTempI`) and plot against time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "file_path = \"../pcrr/3a_run_01.pcrr\"\n",
    "sensor_name = \"irObjTempI\"\n",
    "stop_after_first = True\n",
    "\n",
    "df_sensor_data = extract_sensor_data(file_path, sensor_name, stop_after_first)"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='timestamp'>"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Compute the rolling median of the immersed temperature, with a window of 30 seconds, and plot it.\n",
    "Overlay the rolling median of the immersed UVA trace (`uvaI`) on the same plot."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2 - Reaction Data\n",
    "\n",
    "While PCRR is used as a means of encapsulating chemistry runs in DigitalGlassware, the concept\n",
    " of using XML as a structuring mechanism is quite recent. There are many older datasets which\n",
    " use formats such as RDF, wherein lists of reactions describe the structural change which\n",
    " occurs during the chemistry. This section will focus on a small sample dataset which uses\n",
    " this format\n",
    "\n",
    "To perform this task, install [RDKit](https://www.rdkit.org) to your Anaconda environment.\n",
    "\n",
    "An RD file has been provided under the `data` directory for use in the following tasks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Write a parser to split up `data/spresi-100.rdf` into `$RXN` blocks, which\n",
    "denote individual reactions. A valid reaction starts with `$RXN` and includes\n",
    "every subsequent line until the next `$RXN` block (inclusive) or the\n",
    "end of the file.\n",
    "Everything before the first `$RXN` block can be ignored.\n",
    "<p>\n",
    "Alternatively, there is a Python library which will do this for you, but it's up to you\n",
    "to find it.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Use RDKit to parse each of the `$RXN` text blocks you parsed in above,\n",
    " and print out the SMILES for the reagents and products\n",
    " on the first 5 reactions.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Generate [molecular fingerprints](https://www.rdkit.org/docs/GettingStartedInPython.html#morgan-fingerprints-circular-fingerprints)\n",
    "for all reagents and products and store them in a binary numpy matrix (bonus: use a sparse matrix).\n",
    "Use a radius of 2 and fingerprint length of 1000. Ignore any molecules which throw an exception, and remove them from\n",
    "the final array."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Perform dimensionality reduction on the fingerprints to visualise the data in 2D.\n",
    "Use whether the molecule's fingerprint was a reactant or product as the colour of the point."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Perform clustering on the fingerprints and visualise the results in the same embedding used\n",
    "in the previous question."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrap Up\n",
    "\n",
    "Please bring the completed code in this notebook/code for generating results along to your interview.\n",
    "The code should be executed in real-time unless there is a good reason to avoid this. You will be\n",
    "asked how you completed the tasks and why you did it a certain way, as well as discussion\n",
    "on other ways the tasks could have been performed.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('dm_interview': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "3de1a21ffd7898fcae9c5bf34731e0ef16d60fc6ae355b47869b67b288bf6426"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}